# -*- coding: utf-8 -*-
"""BICS-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R2CZjR1YKRbHg4EgceyunLvz7qTBaPvj

# Project

## Data

```
https://physionet.org/content/sleep-edfx/1.0.0/
```
"""

!wget https://physionet.org/content/sleep-edfx/1.0.0/sleep-cassette/SC4001E0-PSG.edf

!wget https://physionet.org/content/sleep-edfx/1.0.0/sleep-cassette/SC4001EC-Hypnogram.edf

"""# Source"""

!pip install mne

"""## Import"""

import mne
import numpy as np
import pandas as pd
import seaborn as sn
import torch
import matplotlib.pyplot as plt
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
import torch.nn as nn
from torch.utils.data import  DataLoader
from torch import optim
from torch.utils.tensorboard import SummaryWriter
import torch.nn.functional as F
from sklearn.metrics import homogeneity_score

"""## Path to files"""

path = '/content/drive/MyDrive/BICS-1/data/'
# use this path without Google Disc
# path = '/content/' 
patient='SC4001E0-PSG.edf'
annotation='SC4001EC-Hypnogram.edf'

"""## Preprocessing"""

raw = mne.io.read_raw_edf(path+patient, preload=True)
annot = mne.read_annotations(path+annotation)

raw

sleep_stages = pd.DataFrame(columns=['onset','duration', 'stage'])

for x in annot:
  sleep_stages = sleep_stages.append({'onset':x['onset'], 'duration':x['duration'], 'stage':x['description'][-1:]}, ignore_index=True)

sleep_stages

sleep_stages['stage'].unique()

"""Let's delete not reconized sleep-stages ('?')"""

sleep_stages = sleep_stages.loc[sleep_stages['stage'].isin(['1','2','3', '4', 'W', 'R'])]
sleep_stages

items = 5
data = {
        'W': sleep_stages.loc[sleep_stages['stage']=='W']['duration'].values[:items],
        'R': sleep_stages.loc[sleep_stages['stage']=='R']['duration'].values[:items],
        '1': sleep_stages.loc[sleep_stages['stage']=='1']['duration'].values[:items],
        '2': sleep_stages.loc[sleep_stages['stage']=='2']['duration'].values[:items],
        '3': sleep_stages.loc[sleep_stages['stage']=='3']['duration'].values[:items],
        '4': sleep_stages.loc[sleep_stages['stage']=='4']['duration'].values[:items]
        }
sleep_stages_duration = pd.DataFrame(data)
sleep_stages_duration

corr_matrix = sleep_stages_duration.corr()
sn.heatmap(corr_matrix, annot=True)
plt.show()

"""We see strong correlation between durations of stages. So, it will be better to slice all arrays to the same duration. For example '30.0'. Otherwise NN will recognise sleep stages baced on duration. And it is not fully correct behaviour"""

for index, sleep in sleep_stages.iterrows():
  if sleep['duration']>60.0:
    for i in range(int(sleep['duration']//60)):
      sleep_stages = sleep_stages.append({'onset':sleep['onset']+i*60.0, 'duration':60.0, 'stage':sleep['stage']}, ignore_index=True)
sleep_stages

sleep_stages = sleep_stages.loc[sleep_stages['duration']==60]
sleep_stages

signals = list()
for i, s in sleep_stages.iterrows():
  signals.append(raw[:, 	int(s['onset']):int(s['onset'])+int(s['duration'])][0])

eeg_signals = list()
for i, s in enumerate(signals):
  d = dict()
  d['stage'] = sleep_stages.iloc[i]['stage']
  d['signal'] = s
  eeg_signals.append(d)

eeg_signals = pd.DataFrame(eeg_signals)
eeg_signals

"""We have created an array with number of stage and signal"""

items = 5
data = {
        0: preprocessing.normalize([np.hstack(eeg_signals.loc[eeg_signals['stage']=='W']['signal'].values[0])])[0],
        1: preprocessing.normalize([np.hstack(eeg_signals.loc[eeg_signals['stage']=='1']['signal'].values[0])])[0],
        2: preprocessing.normalize([np.hstack(eeg_signals.loc[eeg_signals['stage']=='2']['signal'].values[0])])[0],
        3: preprocessing.normalize([np.hstack(eeg_signals.loc[eeg_signals['stage']=='3']['signal'].values[0])])[0],
        4: preprocessing.normalize([np.hstack(eeg_signals.loc[eeg_signals['stage']=='4']['signal'].values[0])])[0]
        }
sleep_stages_duration = pd.DataFrame(data)
sleep_stages_duration

"""
We can see that now we should find something more difficult than a signal duration"""

sleep_stages.describe()

def visualize_signals(channels, signals, signal_type):
  plt.figure(figsize=(120, 4*channels))
  j = 0
  for i in range(channels):
      plt.subplot(channels, 2, j+1)
      plt.plot(signals[i])
      plt.grid()
      plt.title(f'{signal_type}_{i}')
      j+=2

eeg_signals.loc[eeg_signals['stage']=='W', 'stage'] = 0
eeg_signals.loc[eeg_signals['stage']=='R', 'stage'] = -1
eeg_signals['stage'] = eeg_signals['stage'].astype(int)

channels = eeg_signals['signal'].values[0].shape[0]
signal_type = 2
number = 1
signal = eeg_signals.loc[eeg_signals['stage']==signal_type]['signal'].values[number]
visualize_signals(channels, signal, signal_type)

"""# Train and test dataset and dataloader

# Module
"""

import torch.nn as nn

class Encoder(nn.Module):
    def __init__(self, latent_size):
      super().__init__()
      self.latent_size = latent_size
      hidden_dims = [16, 32, 64, 128, 256, 512]
      modules = []
      in_channels = 7
      for h_dim in hidden_dims[:-1]:
          modules.append(
              nn.Sequential(
                  nn.Conv1d(
                      in_channels=in_channels,
                      out_channels=h_dim,
                      kernel_size=3,
                      stride=2,
                      padding=1,
                  ),
                  nn.BatchNorm1d(h_dim),
                  nn.LeakyReLU(),
              )
          )
          in_channels = h_dim

      modules.append(
          nn.Sequential(
              nn.Conv1d(in_channels=256, out_channels=512, kernel_size=1),
              nn.BatchNorm1d(512),
              nn.LeakyReLU(),
          )
      )
      modules.append(nn.Flatten())
      modules.append(nn.Linear(hidden_dims[-1] * 2, latent_size))

      self.encoder = nn.Sequential(*modules)


    def forward(self,x):

      embedding = self.encoder(x)

      return  embedding  


class Decoder(nn.Module):
    def __init__(self, latent_size):
      super().__init__()
      self.latent_size = latent_size

      hidden_dims = [512, 256, 128, 64, 32, 16] #only 32 channels for 30
      self.linear = nn.Linear(in_features=latent_size, out_features=hidden_dims[0])

      modules = []
      for i in range(len(hidden_dims) - 1):
          modules.append(
              nn.Sequential(
                  nn.ConvTranspose1d(
                      hidden_dims[i],
                      hidden_dims[i + 1],
                      kernel_size=3,
                      stride=2,
                      padding=1,
                      output_padding=1,
                  ),
                  nn.BatchNorm1d(hidden_dims[i + 1]),
                  nn.LeakyReLU(),
              )
          )

      modules.append(
          nn.Sequential(
              nn.ConvTranspose1d(
                  hidden_dims[-1],
                  hidden_dims[-1],
                  kernel_size=3,
                  stride=2,
                  padding=2, #panding = 1 for 30
                  output_padding=1,
              ),
              nn.BatchNorm1d(hidden_dims[-1]),
              nn.LeakyReLU(),
              nn.Conv1d(hidden_dims[-1], out_channels=7, kernel_size=5, padding=1),
              nn.Sigmoid(),
          )
      )

      self.decoder = nn.Sequential(*modules)  
  
    def forward(self,x): 
      x = self.linear(x)
      x = x.view(-1, 512, 1)
      recovered = self.decoder(x)
      return recovered

"""##Smoke test"""

import torch
encoder = Encoder(2)
dummy = torch.randn((1, 7, 60))
print("Encoder In",dummy.shape)
embedding = encoder(dummy)
print("encoder Out",embedding.shape)


decoder =Decoder(2)
recovered = decoder(embedding)
print("Decoder out",recovered.shape)

assert( dummy.shape == recovered.shape) ,"Decoder out shape must be equal to input shape"

"""# AutoEncoder """

class AutoEncoder(nn.Module):
  def __init__(self, latent_size):
    super().__init__()
    self.latent_size = latent_size
    self.encoder = Encoder(latent_size)
    self.decoder = Decoder(latent_size) 

  def forward(self,x):
    embedding = self.encoder(x)
    recovered_x = self.decoder(embedding)
    return recovered_x, embedding

"""# Dataset"""

class EEGDataset(torch.utils.data.Dataset):
    def __init__(self, signal, stage):
        self.stages = stage
        self.eeg = signal

    def __len__(self):
        return len(self.stages)

    def __getitem__(self, idx):
        eeg = self.eeg[idx]
        stage = self.stages[idx]
        return eeg, stage

indixes = np.arange(len(eeg_signals['stage']))
X_train, X_test, y_train, y_test,  indexes_train, indexes_test = train_test_split(eeg_signals['signal'], eeg_signals['stage'], indixes, test_size=0.2, stratify =  eeg_signals['stage'])
# X_train, X_test, y_train, y_test,  indexes_train, indexes_test = train_test_split(X_train, y_train, indexes_train, test_size=0.2, stratify =  y_train)

train_ds = EEGDataset(torch.tensor(np.stack(np.asarray(X_train)), dtype=torch.double), torch.tensor(np.asarray(y_train), dtype=torch.int))
test_ds = EEGDataset(torch.tensor(np.stack(np.asarray(X_test)), dtype=torch.double), torch.tensor(np.asarray(y_test), dtype=torch.int))

train_dataloader = DataLoader(train_ds,shuffle=True,batch_size=64)
test_dataloader = DataLoader(test_ds,shuffle=False,batch_size=128)

"""
# Train"""

def train(model, train_dataloader, test_dataloader, epoch = 15):
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
  writer = SummaryWriter(comment = "autoencoder")
  optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-4)
  model.to(device)
  model.train()
  for epoch in range(epoch):
    for img_batch, labels in train_dataloader:
      optimizer.zero_grad()
      output, latent =  model(img_batch.to(device))
      loss = F.mse_loss(output.to(device), torch.sigmoid(img_batch.to(device)))
      loss.backward()
      optimizer.step()
    writer.add_scalar('Loss/train',loss.cpu().item(),epoch)
    print("Epoch {} Loss {:.4f}".format(epoch,loss.item()))
    writer.flush()
  writer.close()    
  return model

# !rm -r /content/runs/

model = AutoEncoder(128)
epoch = 20
model = train(model.double(),train_dataloader,test_dataloader, epoch)

# Commented out IPython magic to ensure Python compatibility.
logs_base_dir = "runs"
# %load_ext tensorboard
# %tensorboard --logdir {logs_base_dir}

# Commented out IPython magic to ensure Python compatibility.
from torchvision.models import resnet18
import os
import shutil

resnet_original = resnet18()
print(resnet_original)


# Helper method to run Tensorboard in Colab
def reinit_tensorboard(clear_log = True):
  # Directory for log files
  logs_base_dir = "runs"
  if clear_log:
    # Clear logs
    shutil.rmtree(logs_base_dir, ignore_errors = True)
    os.makedirs(logs_base_dir, exist_ok=True)
  # Colab magic
#   %load_ext tensorboard
#   %tensorboard --logdir {logs_base_dir}

import torch
from torch.utils.tensorboard import SummaryWriter

reinit_tensorboard()
writer = SummaryWriter(comment = "autoencoder")

dummy_input = torch.randn([1,7,60])
model = AutoEncoder(128)
epoch = 600
writer.add_graph(model, dummy_input)
writer.flush()
writer.close()

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
img = mpimg.imread('/content/screenshot.png')
imgplot = plt.imshow(img)
plt.show()

"""# Test Model"""

def run_eval(
    autorencoder,
    loader):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    real = []
    reconstr = []
    latent = []
    labels = []
    with torch.no_grad():
        for data, lab in loader:
            labels.append(lab.numpy())
            real.append(data.numpy())
            data = data.to(device)
            lab = lab.to(device)
            rec, emb = autorencoder(data.to(device))
            latent.append(emb.cpu().numpy())
            reconstr.append(rec.cpu().numpy())

    result = {}
    real = np.concatenate(real)
    result["real"] = real.squeeze()
    latent = np.concatenate(latent)
    result["latent"] = latent
    reconstr = np.concatenate(reconstr)
    result["reconstr"] = reconstr.squeeze()
    labels = np.concatenate(labels)
    result["labels"] = labels
    return result

autoencoder = model.eval()

run_res = run_eval(autoencoder, test_dataloader)

run_res_pd = list()
for i, s in enumerate(run_res['reconstr']):
  d = dict()
  d['reconstr'] = s
  d['real'] = run_res['real'][i]
  d['labels'] = run_res['labels'][i]
  run_res_pd.append(d)

def visualize_signals_2(channels, signal_real, signal_fake, signal_type):
  plt.figure(figsize=(120, 4*channels))
  j = 0
  for i in range(channels):
      plt.subplot(channels, 2, j+1)
      plt.plot(signal_real[i])
      plt.plot(signal_fake[i])
      plt.grid()
      plt.title(f'{signal_type}_{i}')
      plt.legend(['Real', 'Fake'])
      j+=2

run_res_pd = pd.DataFrame(run_res_pd)
channels = run_res_pd['reconstr'].values[0].shape[0]
signal_type = 2
number = 1
signal_fake = run_res_pd.loc[run_res_pd['labels']==signal_type]['reconstr'].values[number]
signal_real = run_res_pd.loc[run_res_pd['labels']==signal_type]['real'].values[number]
visualize_signals_2(channels, signal_real, signal_fake, signal_type)

def plot_manifold(latent_r, labels=None, alpha=0.5):
    plt.figure(figsize=(10, 10))
    plt.scatter(latent_r[:, 0], latent_r[:, 1], c=labels, alpha=0.9)
    plt.colorbar()
    plt.show()

plot_manifold(run_res['latent'], run_res['labels'])



"""# Clusters

## Code from matplotlib library
"""

import numpy as np

from sklearn.cluster import DBSCAN
from sklearn import metrics
from sklearn.preprocessing import StandardScaler

def plot_DBSCAN(latent, labels_true, eps=0.3, min_samples=15):
  X = latent
  db = DBSCAN(eps=eps, min_samples=min_samples).fit(X)
  core_samples_mask = np.zeros_like(db.labels_, dtype=bool)
  core_samples_mask[db.core_sample_indices_] = True
  labels = db.labels_
  labels_true = labels_true
  # Number of clusters in labels, ignoring noise if present.
  n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)
  n_noise_ = list(labels).count(-1)

  print("Estimated number of clusters: %d" % n_clusters_)
  print("Estimated number of noise points: %d" % n_noise_)
  print("Homogeneity: %0.3f" % metrics.homogeneity_score(labels_true, labels))
 
  import matplotlib.pyplot as plt

  # Black removed and is used for noise instead.
  unique_labels = set(labels)
  colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]
  for k, col in zip(unique_labels, colors):
      if k == -1:
          # Black used for noise.
          col = [0, 0, 0, 1]

      class_member_mask = labels == k
      # without noise
      if k!=-1:
        xy = X[class_member_mask & core_samples_mask]
        plt.plot(
            xy[:, 0],
            xy[:, 1],
            "o",
            markerfacecolor=tuple(col),
            markeredgecolor="k",
            markersize=14,
        )

        xy = X[class_member_mask & ~core_samples_mask]
        plt.plot(
            xy[:, 0],
            xy[:, 1],
            "o",
            markerfacecolor=tuple(col),
            markeredgecolor="k",
            markersize=6,
        )

  plt.title("Estimated number of clusters: %d" % n_clusters_)
  plt.show()

plot_DBSCAN(run_res['latent'], y_test, eps=0.15, min_samples=4)

db = DBSCAN(eps=0.15, min_samples=4).fit(run_res['latent'])
labels = db.labels_

"""# Result"""

sleep_stages_result = sleep_stages.iloc[indexes_test]

result = {
        'start_time': sleep_stages_result['onset'].values,
        'end_time': sleep_stages_result['onset'].values + sleep_stages_result['duration'].values,
        'type_from_nn': labels,
        'type_from_doctor': y_test,
        'homogenity': metrics.homogeneity_score(y_test, labels),
        }
result = pd.DataFrame(result)
result

result.to_csv('result.csv', sep='\t')